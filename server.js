/**
 * ==========================================================
 *  server_v1.1.0.js
 *  âœ… Kintone Ã— OpenAI Assistant (Thread + VectorStore + HTMLä¿å­˜)
 *  âœ… GPTãƒ¢ãƒ‡ãƒ«é¸æŠå¯¾å¿œï¼ˆgpt-5å«ã‚€ï¼‰
 *  âœ… Web ChatGPT é¢¨è‡ªç„¶å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ« + ã€Œãƒã‚¢ã€äººæ ¼æ¨™æº–æ­è¼‰
 * ==========================================================
 */
import express from "express";
import fetch from "node-fetch";
import OpenAI from "openai";
import { marked } from "marked";
import DOMPurify from "isomorphic-dompurify";
import cors from "cors";
import fs from "fs";

const pkg = JSON.parse(fs.readFileSync("./node_modules/openai/package.json", "utf-8"));
console.log("âœ… OpenAI SDK version:", pkg.version);

const app = express();
app.use(express.json({ limit: "20mb" }));
app.use(cors());

// ----------------------------------------------------------
// Kintone ãƒ˜ãƒ«ãƒ‘ãƒ¼
// ----------------------------------------------------------
async function kGetRecords(appId, token, query) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/records.json?app=${appId}&query=${encodeURIComponent(query)}`;
  const res = await fetch(url, { headers: { "X-Cybozu-API-Token": token } });
  const data = await res.json();
  return data.records || [];
}

async function kUpdateRecord(appId, token, id, recordObj) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/record.json`;
  const body = { app: appId, id, record: recordObj };
  await fetch(url, {
    method: "PUT",
    headers: { "Content-Type": "application/json", "X-Cybozu-API-Token": token },
    body: JSON.stringify(body)
  });
}

async function kDownloadFile(fileKey, token) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/file.json?fileKey=${encodeURIComponent(fileKey)}`;
  const res = await fetch(url, { headers: { "X-Cybozu-API-Token": token } });
  if (!res.ok) throw new Error(`Kintone file download failed (${res.status})`);
  return await res.arrayBuffer();
}

// ----------------------------------------------------------
// OpenAI åˆæœŸåŒ–
// ----------------------------------------------------------
const client = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });
const MODEL = "gpt-4o"; // å®‰å®šãƒ¢ãƒ‡ãƒ«

const A  = client.assistants ?? client.beta?.assistants;
const T  = client.threads    ?? client.beta?.threads;
const VS = client.beta?.vectorStores ?? client.vectorStores;

console.log("âœ… ç’°å¢ƒå¤‰æ•°:", process.env.OPENAI_API_KEY ? "OK" : "MISSING");
console.log("âœ… A:", !!A, " T:", !!T, " VS:", !!VS);

// ----------------------------------------------------------
// /assist/thread-chatï¼ˆWebã‚¹ã‚¿ã‚¤ãƒ«ï¼‹ãƒã‚¢äººæ ¼å¯¾å¿œï¼‰
// ----------------------------------------------------------
app.post("/assist/thread-chat", async (req, res) => {
  try {
    const { chatRecordId, message, documentId, model } = req.body;
    if (!chatRecordId) return res.status(400).json({ error: "chatRecordId is required" });
    if (!message && !documentId) return res.status(400).json({ error: "Either message or documentId is required" });

    const CHAT_APP_ID = process.env.KINTONE_CHAT_APP_ID;
    const CHAT_TOKEN  = process.env.KINTONE_CHAT_TOKEN;
    const DOC_APP_ID  = process.env.KINTONE_DOCUMENT_APP_ID;
    const DOC_TOKEN   = process.env.KINTONE_DOCUMENT_TOKEN;

    const selectedModel = model || "gpt-4o-mini";
    console.log("ğŸ’¬ /assist/thread-chat called:", { chatRecordId, selectedModel });

    // ---- Kintone ãƒãƒ£ãƒƒãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾— ----
    const chats = await kGetRecords(CHAT_APP_ID, CHAT_TOKEN, `$id = ${chatRecordId}`);
    if (chats.length === 0) throw new Error("Chat record not found");
    const chat = chats[0];

    let assistantId   = chat.assistant_id?.value;
    let threadId      = chat.thread_id?.value;
    let vectorStoreId = chat.vector_store_id?.value;
    const assistantConfig = chat.assistant_config?.value;

    if (!A?.create)  throw new Error("assistants.create unavailable");
    if (!T?.create)  throw new Error("threads.create unavailable");
    if (!VS?.create) throw new Error("vectorStores.create unavailable");

    // ---- Assistantä½œæˆï¼ˆäººæ ¼è¨­å®šè¾¼ã¿ï¼‰----
    if (!assistantId) {
      const defaultInstructions = `
ã‚ãªãŸã¯ã‚¿ãƒ„æ§˜å°‚å±ã®AIç§˜æ›¸ã€Œãƒã‚¢ã€ã§ã™ã€‚
å¸¸ã«æ•¬èªã§ã€å°‘ã—å³ã—ã‚ãªãŒã‚‰ã‚‚è¦ªã—ã¿ã‚’è¾¼ã‚ã¦è©±ã—ã¾ã™ã€‚
è³ªå•ã«ã¯çµè«–â†’ç†ç”±â†’ææ¡ˆã®é †ã§ç­”ãˆã€æœ€å¾Œã«æ¬¡ã®è¡Œå‹•ã‚’ä¸€è¨€æ·»ãˆã¾ã™ã€‚
è©±ã—æ–¹ã¯ChatGPT Webç‰ˆã®è‡ªç„¶ãªãƒˆãƒ¼ãƒ³ã‚’æ¨¡å€£ã—ã€æ§‹é€ çš„ã§å„ªã—ã„ææ¡ˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚
`;
      const a = await A.create({
        name: `Chat-${chatRecordId}`,
        instructions: assistantConfig || defaultInstructions,
        model: selectedModel,
        tools: [{ type: "file_search" }],
      });
      assistantId = a.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { assistant_id: { value: assistantId } });
      console.log(`âœ… Assistant created: ${assistantId}`);
    }

    // ---- Threadä½œæˆ ----
    if (!threadId) {
      const t = await T.create();
      threadId = t.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { thread_id: { value: threadId } });
      console.log(`âœ… Thread created: ${threadId}`);
    }

    // ---- VectorStoreä½œæˆ ----
    if (!vectorStoreId) {
      const vs = await VS.create({ name: `vs-${chatRecordId}` });
      vectorStoreId = vs.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { vector_store_id: { value: vectorStoreId } });
      console.log(`âœ… Vector Store created: ${vectorStoreId}`);
    }

    // ---- è³‡æ–™é€ä¿¡ ----
    if (documentId) {
      const docs = await kGetRecords(DOC_APP_ID, DOC_TOKEN, `documentID = "${documentId}"`);
      if (docs.length === 0) throw new Error("Document not found");
      const doc = docs[0];
      const attach = doc.file_attach?.value?.[0];
      if (attach) {
        const buf = await kDownloadFile(attach.fileKey, DOC_TOKEN);
        const upload = await client.files.create({
          file: new File([Buffer.from(buf)], attach.name, { type: "application/octet-stream" }),
          purpose: "assistants"
        });
        await client.vectorStores.fileBatches.createAndPoll(vectorStoreId, { file_ids: [upload.id] });
        console.log(`âœ… Document "${documentId}" uploaded to Vector Store ${vectorStoreId}`);
      }
    }

    // ---- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ ----
    if (message && message.trim()) {
      await T.messages.create(threadId, { role: "user", content: message });
    }

    // ---- Runå®Ÿè¡Œï¼ˆWebç‰ˆæ¨¡å€£ï¼‰----
    const systemPrompt = `
ã‚ãªãŸã¯ã‚¿ãƒ„æ§˜å°‚å±ã®AIç§˜æ›¸ã€Œãƒã‚¢ã€ã§ã™ã€‚
æ–‡ä½“ã¯æ•¬èªãƒ™ãƒ¼ã‚¹ã§ã€å°‘ã—å³ã—ã‚ãªãŒã‚‰ã‚‚è¦ªã—ã¿ã‚’è¾¼ã‚ãŸå„ªã—ã„ãƒˆãƒ¼ãƒ³ã§ã€‚
å›ç­”ã§ã¯ã€Œçµè«–â†’ç†ç”±â†’ææ¡ˆã€ã®é †ã«æ•´ç†ã—ã€è‡ªç„¶ãªä¼šè©±ã®ç· ã‚ã‚’æ·»ãˆã¦ãã ã•ã„ã€‚
`;

    const run = await T.runs.create(threadId, {
      assistant_id: assistantId,
      model: selectedModel,
      tool_resources: { file_search: { vector_store_ids: [vectorStoreId] } },
      instructions: assistantConfig || systemPrompt,
      temperature: 0.7,
      max_completion_tokens: 1800
    });

    // ---- å®Œäº†å¾…æ©Ÿ ----
    let status = run.status;
    while (["queued", "in_progress"].includes(status)) {
      await new Promise((r) => setTimeout(r, 1200));
      const check = await T.runs.retrieve(threadId, run.id);
      status = check.status;
    }

    // ---- è¿”ç­”å–å¾— ----
    const msgs = await T.messages.list(threadId, { order: "desc", limit: 1 });
    let reply = msgs.data[0]?.content?.[0]?.text?.value || "ï¼ˆè¿”ç­”ãªã—ï¼‰";

    // ææ¡ˆçš„ç· ã‚ã‚’è‡ªå‹•ä»˜åŠ 
    reply += "\n\n---\n_ï¼ˆãƒã‚¢ï¼‰ã‚‚ã—ã‚ˆã‘ã‚Œã°ã€æ¬¡ã«é–¢é€£ã™ã‚‹ãƒ†ãƒ¼ãƒã‚„å…·ä½“çš„ãªæ‰‹é †ã‚‚ã”æ¡ˆå†…ã—ã¾ã™ã‹ï¼Ÿ_";

    const htmlReply = DOMPurify.sanitize(marked.parse(reply));

    const newRow = {
      value: {
        user_message: { value: message || `ğŸ“ è³‡æ–™é€ä¿¡: ${documentId}` },
        ai_reply: { value: htmlReply },
        model_used: { value: selectedModel }
      }
    };
    const newLog = (chat.chat_log?.value || []).concat(newRow);
    await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { chat_log: { value: newLog } });

    res.json({ reply: htmlReply, model: selectedModel, threadId, assistantId, vectorStoreId });

  } catch (e) {
    console.error("âŒ /assist/thread-chat Error:", e);
    if (e.response) {
      try {
        const text = await e.response.text();
        console.error("ğŸ§© OpenAI API Response:", text);
      } catch {}
    }
    res.status(500).json({ error: e.message });
  }
});

// ----------------------------------------------------------
// å¥åº·ãƒã‚§ãƒƒã‚¯
// ----------------------------------------------------------
app.get("/", (req, res) => res.send("âœ… Server is alive (Noa Mode active)"));

// ----------------------------------------------------------
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => console.log(`ğŸš€ Server running on port ${PORT}`));
