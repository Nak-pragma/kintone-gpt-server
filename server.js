import express from "express";
import fetch from "node-fetch";
import dotenv from "dotenv";
import OpenAI from "openai";
import { marked } from "marked";
import DOMPurify from "isomorphic-dompurify";

dotenv.config();

const app = express();

/* 1ï¸âƒ£ JSONãƒœãƒ‡ã‚£ã‚’æœ€åˆã«å‡¦ç† */
app.use(express.json({ limit: "2mb" }));

/* ==========================================================
 * âœ… 1. CORSè¨­å®šï¼ˆãƒ—ãƒªãƒ•ãƒ©ã‚¤ãƒˆå¯¾å¿œï¼‰
 * ========================================================== */
app.use((req, res, next) => {
  res.header("Access-Control-Allow-Origin", "*");
  res.header("Access-Control-Allow-Headers", "Origin, X-Requested-With, Content-Type, Accept");
  res.header("Access-Control-Allow-Methods", "GET, POST, OPTIONS");
  if (req.method === "OPTIONS") {
    return res.sendStatus(200);
  }
  next();
});

/* ==========================================================
 * âœ… 2. /project-chat : ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ–‡è„ˆï¼‹è³‡æ–™ã§ã®AIè­°è«–API
 * ========================================================== */
app.post("/project-chat", async (req, res) => {
  try {
    const { projectId, documentId, message } = req.body;
    if (!projectId || !documentId || !message) {
      return res.status(400).json({ error: "Missing projectId, documentId, or message" });
    }

    // --- ç’°å¢ƒå¤‰æ•° ---
    const KINTONE_DOMAIN = process.env.KINTONE_DOMAIN;
    const PROJECT_APP_ID = process.env.KINTONE_PROJECT_APP_ID;
    const DOCUMENT_APP_ID = process.env.KINTONE_DOCUMENT_APP_ID;
    const PROJECT_API_TOKEN = process.env.KINTONE_PROJECT_TOKEN;
    const DOCUMENT_API_TOKEN = process.env.KINTONE_DOCUMENT_TOKEN;

    // --- å…±é€šé–¢æ•°ï¼šKintoneãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾— ---
    const getKintoneRecord = async (appId, apiToken, query) => {
      const url = `https://${KINTONE_DOMAIN}/k/v1/records.json?app=${appId}&query=${encodeURIComponent(query)}`;
      const response = await fetch(url, {
        headers: { "X-Cybozu-API-Token": apiToken }
      });
      const data = await response.json();
      if (!data.records || data.records.length === 0) return null;
      return data.records[0];
    };

    // --- ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ± ---
    const projectRecord = await getKintoneRecord(PROJECT_APP_ID, PROJECT_API_TOKEN, `projectID = "${projectId}"`);
    if (!projectRecord) return res.status(404).json({ error: "Project not found" });

    // --- è³‡æ–™æƒ…å ± ---
    const documentRecord = await getKintoneRecord(DOCUMENT_APP_ID, DOCUMENT_API_TOKEN, `documentID = "${documentId}"`);
    if (!documentRecord) return res.status(404).json({ error: "Document not found" });

    // --- GPTã¸æ¸¡ã™ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ ---
    const contextPrompt = `
ã‚ãªãŸã¯è£½é€ æ¥­R&Dæ”¯æ´ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€Œãƒã‚¢ã€ã§ã™ã€‚
æ¬¡ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã¨è³‡æ–™ã‚’ã‚‚ã¨ã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¨ã®è­°è«–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„ã€‚
å‡ºå…¸ãƒ‡ãƒ¼ã‚¿ã®å¼•ç”¨ã¯ä¸è¦ã§ã™ã€‚

ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã€‘
ç›®çš„: ${projectRecord.ç›®çš„?.value || "æœªè¨­å®š"}
ç›®æ¨™: ${projectRecord.ç›®æ¨™?.value || "æœªè¨­å®š"}
ã‚¹ã‚³ãƒ¼ãƒ—: ${projectRecord.ã‚¹ã‚³ãƒ¼ãƒ—?.value || "æœªè¨­å®š"}

ã€è³‡æ–™æƒ…å ±ã€‘
ã‚¿ã‚¤ãƒˆãƒ«: ${documentRecord.ã‚¿ã‚¤ãƒˆãƒ«?.value || "æœªè¨­å®š"}
æ¦‚è¦: ${documentRecord.æ¦‚è¦?.value || "æœªè¨­å®š"}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚„ã‚³ãƒ¡ãƒ³ãƒˆ:
${message}
`;

    // --- GPTå‘¼ã³å‡ºã— ---
    const completion = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-5", // ç¾è¡Œç’°å¢ƒã¨åˆã‚ã›ã‚‹
        messages: [
          { role: "system", content: "ã‚ãªãŸã¯è£½é€ æ¥­R&Dãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ”¯æ´AIã€Œãƒã‚¢ã€ã§ã™ã€‚èª å®Ÿã«ã€ç°¡æ½”ã«ç­”ãˆã¦ãã ã•ã„ã€‚" },
          { role: "user", content: contextPrompt }
        ]
      })
    });

    const result = await completion.json();
    const reply = result?.choices?.[0]?.message?.content || "ï¼ˆè¿”ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰";

    res.json({ reply });
  } catch (error) {
    console.error("âŒ /project-chat Error:", error);
    res.status(500).json({ error: "Internal Server Error" });
  }
});


/* ==========================================================
 * âœ… 3ï¸âƒ£ /assist/thread-chat : Assistant+Thread+Vector Storeå¯¾å¿œç‰ˆ
 * ========================================================== */
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// --- Kintoneå…±é€šé–¢æ•° ---
async function kGetRecords(appId, token, query) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/records.json?app=${appId}&query=${encodeURIComponent(query)}`;
  const res = await fetch(url, { headers: { "X-Cybozu-API-Token": token } });
  const data = await res.json();
  return data.records || [];
}
async function kUpdateRecord(appId, token, id, recordObj) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/record.json`;
  const body = { app: appId, id, record: recordObj };
  await fetch(url, {
    method: "PUT",
    headers: {
      "Content-Type": "application/json",
      "X-Cybozu-API-Token": token
    },
    body: JSON.stringify(body)
  });
}
async function kDownloadFile(fileKey, token) {
  const url = `https://${process.env.KINTONE_DOMAIN}/k/v1/file.json?fileKey=${encodeURIComponent(fileKey)}`;
  const res = await fetch(url, { headers: { "X-Cybozu-API-Token": token } });
  if (!res.ok) throw new Error(`Kintone file download failed (${res.status})`);
  return await res.arrayBuffer();
}

// --- /assist/thread-chat å®Ÿè£… ---
app.post("/assist/thread-chat", async (req, res) => {
  try {
    const { chatRecordId, message, documentId } = req.body;
    if (!chatRecordId || (!message && !documentId)) {
      return res.status(400).json({ error: "Missing chatRecordId or message" });
    }

    // --- ç’°å¢ƒå¤‰æ•° ---
    const CHAT_APP_ID = process.env.KINTONE_CHAT_APP_ID;
    const CHAT_TOKEN = process.env.KINTONE_CHAT_TOKEN;
    const DOC_APP_ID = process.env.KINTONE_DOCUMENT_APP_ID;
    const DOC_TOKEN = process.env.KINTONE_DOCUMENT_TOKEN;

    // --- ãƒãƒ£ãƒƒãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰å–å¾— ---
    const chats = await kGetRecords(CHAT_APP_ID, CHAT_TOKEN, `$id = ${chatRecordId}`);
    if (chats.length === 0) throw new Error("Chat record not found");
    const chat = chats[0];

    // --- æ—¢å­˜IDå–å¾—ã¾ãŸã¯æ–°è¦ä½œæˆ ---
    let assistantId = chat.assistant_id?.value;
    let threadId = chat.thread_id?.value;
    let vectorStoreId = chat.vector_store_id?.value;
    const assistantConfig = chat.assistant_config?.value || "ã‚ãªãŸã¯èª å®ŸãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚";

    // Assistantç”Ÿæˆ
    if (!assistantId) {
      const a = await openai.beta.assistants.create({
        name: `Chat-${chatRecordId}`,
        instructions: assistantConfig,
        model: "gpt-4o",
        tools: [{ type: "retrieval" }]
      });
      assistantId = a.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { assistant_id: { value: assistantId } });
    }

    // Threadç”Ÿæˆ
    if (!threadId) {
      const t = await openai.beta.threads.create();
      threadId = t.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { thread_id: { value: threadId } });
    }

    // Vector Storeç”Ÿæˆ
    if (!vectorStoreId) {
      const vs = await openai.beta.vectorStores.create({ name: `vs-${chatRecordId}` });
      vectorStoreId = vs.id;
      await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { vector_store_id: { value: vectorStoreId } });
    }

    // --- è³‡æ–™é€ä¿¡ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆ ---
    if (documentId) {
      const docs = await kGetRecords(DOC_APP_ID, DOC_TOKEN, `documentID = "${documentId}"`);
      if (docs.length === 0) throw new Error("Document not found");
      const doc = docs[0];
      const attach = doc.file_attach?.value?.[0];
      if (attach) {
        const buf = await kDownloadFile(attach.fileKey, DOC_TOKEN);
        const upload = await openai.files.create({
          file: new File([Buffer.from(buf)], attach.name, { type: "application/octet-stream" }),
          purpose: "assistants"
        });
        await openai.beta.vectorStores.fileBatches.uploadAndPoll(vectorStoreId, { file_ids: [upload.id] });
        console.log(`âœ… Document "${documentId}" uploaded to Vector Store ${vectorStoreId}`);
      }
    }

    // --- ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè©±ã‚’Threadã«è¿½åŠ  ---
    if (message && message.trim()) {
      await openai.beta.threads.messages.create(threadId, { role: "user", content: message });
    }

    // --- Runå®Ÿè¡Œï¼ˆVector Storeå‚ç…§ï¼‰ ---
    const run = await openai.beta.threads.runs.create(threadId, {
      assistant_id: assistantId,
      tool_resources: { vector_store_ids: [vectorStoreId] },
      instructions: "æ—¥æœ¬èªã§è«–ç†çš„ã‹ã¤æ§‹é€ çš„ã«å›ç­”ã—ã¦ãã ã•ã„ã€‚"
    });

    // --- å®Ÿè¡Œå®Œäº†å¾…ã¡ ---
    let status = run.status;
    while (["queued", "in_progress"].includes(status)) {
      await new Promise(r => setTimeout(r, 1200));
      const check = await openai.beta.threads.runs.retrieve(threadId, run.id);
      status = check.status;
    }

    // --- æœ€æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å–å¾— ---
    const msgs = await openai.beta.threads.messages.list(threadId, { order: "desc", limit: 1 });
    const reply = msgs.data[0]?.content?.[0]?.text?.value || "ï¼ˆè¿”ç­”ãªã—ï¼‰";

    // --- Markdownâ†’HTMLå¤‰æ›ï¼‹ã‚µãƒ‹ã‚¿ã‚¤ã‚º ---
    const htmlReply = DOMPurify.sanitize(marked.parse(reply));

    // --- Kintoneå±¥æ­´æ›´æ–°ï¼ˆHTMLä¿å­˜ï¼‰ ---
    const newRow = {
      value: {
        user_message: { value: message || `ğŸ“ è³‡æ–™é€ä¿¡: ${documentId}` },
        ai_reply: { value: htmlReply }
      }
    };
    const newLog = (chat.chat_log?.value || []).concat(newRow);
    await kUpdateRecord(CHAT_APP_ID, CHAT_TOKEN, chat.$id.value, { chat_log: { value: newLog } });

    res.json({ reply: htmlReply, threadId, assistantId, vectorStoreId });
  } catch (e) {
    console.error("âŒ /assist/thread-chat Error:", e);
    res.status(500).json({ error: e.message });
  }
});





/* ==========================================================
 * â‘¡ è­°äº‹éŒ²è¦ç´„APIï¼ˆæ—¢å­˜ï¼‰
 * ========================================================== */
app.post("/summary", async (req, res) => {
  try {
    const { text } = req.body;
    if (!text) return res.status(400).json({ error: "Missing text field" });

    const completion = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-5",
        messages: [
          {
            role: "system",
            content:
              "ã‚ãªãŸã¯æ—¥æœ¬èªã®ä¼šè­°è­°äº‹éŒ²ã‚’è¦ç´„ã™ã‚‹ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚é‡è¦è«–ç‚¹ãƒ»æ±ºå®šäº‹é …ãƒ»æ¬¡å›å¯¾å¿œã®3åŒºåˆ†ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚"
          },
          { role: "user", content: text }
        ]
      })
    });

    const result = await completion.json();
    const summary = result?.choices?.[0]?.message?.content ?? "ï¼ˆè¦ç´„ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸï¼‰";
    res.json({ summary });
  } catch (error) {
    console.error("Summary API Error:", error);
    res.status(500).json({ error: "Summary API failed" });
  }
});

/* ==========================================================
 * â‘¢ Webã‚µã‚¤ãƒˆè¦ç´„APIï¼ˆæ—¢å­˜ï¼‰
 * ========================================================== */
app.post("/site-summary", async (req, res) => {
  console.log("ğŸ“© POST /site-summary reached");
  try {
    const { url } = req.body;
    console.log("URL received:", url);

    if (!url) return res.status(400).json({ error: "Missing url" });

    const completion = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        "Authorization": `Bearer ${process.env.OPENAI_API_KEY}`
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "ã‚ãªãŸã¯Webã‚µã‚¤ãƒˆã®å†…å®¹ã‚’æ—¥æœ¬èªã§ç°¡æ½”ã«è¦ç´„ã™ã‚‹AIã§ã™ã€‚" },
          { role: "user", content: `æ¬¡ã®ã‚µã‚¤ãƒˆã‚’è¦ç´„ã—ã¦ãã ã•ã„ï¼š${url}` }
        ]
      })
    });

    console.log("âœ… OpenAI API responded (status):", completion.status);
    const result = await completion.json();

    const messageContent = result?.choices?.[0]?.message?.content || "è¦ç´„çµæœãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚";
    console.log("ğŸ§© Summary Text:", messageContent);
    res.json({ summary: messageContent });
  } catch (error) {
    console.error("âŒ Site Summary Error:", error);
    res.status(500).json({ error: error.message });
  }
});

/* ==========================================================
 * â‘£ å‹•ä½œç¢ºèªãƒ«ãƒ¼ãƒˆ
 * ========================================================== */
if (process.env.NODE_ENV !== "production") {
  app.get("/", (req, res) => res.send("âœ… Pragma GPT Relay Server running (dev mode)"));
}

/* ==========================================================
 * â‘¤ ãƒãƒ¼ãƒˆè¨­å®š
 * ========================================================== */
const port = process.env.PORT || 3000;
app.listen(port, () => console.log(`ğŸš€ Server running on port ${port}`));
